{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00a1053",
   "metadata": {},
   "source": [
    "# Importing Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25dd709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324ff61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chiangwe/anaconda3/envs/NetHawkes/bin/python\n"
     ]
    }
   ],
   "source": [
    "#============ Importing Packages ============# \n",
    "\n",
    "#--------- Drawing Packages ---------#\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator, NullFormatter, LogLocator)\n",
    "from set_size import set_size\n",
    "from collections import Counter\n",
    "\n",
    "#--------- Tensorflow Packages ---------#\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "#============== Packages for word2vec ==============#\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "#============== Packages for classification ==============#\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#--------- Utilities Packages ---------#\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import os\n",
    "import re\n",
    "import pdb\n",
    "import shelve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import class_weight\n",
    "import enchant\n",
    "\n",
    "import nltk\n",
    "import obspy\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('word_tokenize')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import words as dict_w\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Scipy Signal\n",
    "from scipy import signal\n",
    "\n",
    "# Detrend the Signal\n",
    "from obspy.signal.detrend import polynomial\n",
    "\n",
    "#--------- Remove Warnings ---------#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e76266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42aed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2447d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1395998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ba74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd0378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b89ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac2da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6fbd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3d751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========= Read in =========#\n",
    "df = pd.read_csv('Eluvio_DS_Challenge_processes.csv')\n",
    "#display( df.sort_values('up_votes', ascending=False).head(5)['title'].values )\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',  np.unique(df['label']), df['label'])\n",
    "class_weights = dict(zip( np.unique(df['label']), class_weights))\n",
    "\n",
    "\n",
    "df = df[ df['title_clean'].apply(lambda x: type(x)==str) ] \n",
    "y_true = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d423bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========= TDIDF =========#\n",
    "\n",
    "#print(  df['title_clean'].apply(lambda x: type(x)!=str ).sum()  )\n",
    "bow_converter = CountVectorizer()\n",
    "x = bow_converter.fit_transform(df['title_clean'])\n",
    "\n",
    "words = bow_converter.get_feature_names()\n",
    "\n",
    "bigram_converter = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[2,2]) \n",
    "trigram_converter = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[3,3])\n",
    "\n",
    "tfidf_transform = TfidfTransformer(norm=None)\n",
    "X_tfidf = tfidf_transform.fit_transform(x)\n",
    "\n",
    "X_tfidf = normalize(X_tfidf,axis=1)\n",
    "\n",
    "#========= ===  =========#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf3991ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========== PCS ===================#\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_new = SelectKBest(chi2, k=np.round(X_tfidf.shape[1]/4).astype(int) ).fit_transform(X_tfidf, y_true)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_tfidf_pca = pca.fit_transform(X_new.toarray())\n",
    "X_new = np.concatenate((X_new.toarray(), X_tfidf_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5116905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504717, 2811)\n",
      "(504717, 10)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d07d1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 744.00, NNZs: 2821, Bias: 52.910881, T: 338160, Avg. loss: 195.550404\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 390.17, NNZs: 2821, Bias: 26.410292, T: 676320, Avg. loss: 39.461048\n",
      "Total training time: 3.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 255.24, NNZs: 2821, Bias: 16.735255, T: 1014480, Avg. loss: 22.657354\n",
      "Total training time: 5.32 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 182.81, NNZs: 2821, Bias: 12.209250, T: 1352640, Avg. loss: 16.064742\n",
      "Total training time: 7.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 147.22, NNZs: 2821, Bias: 8.744431, T: 1690800, Avg. loss: 12.091957\n",
      "Total training time: 8.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 123.30, NNZs: 2821, Bias: 7.901758, T: 2028960, Avg. loss: 10.081349\n",
      "Total training time: 10.69 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 107.08, NNZs: 2821, Bias: 6.525889, T: 2367120, Avg. loss: 8.698781\n",
      "Total training time: 12.51 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 94.99, NNZs: 2821, Bias: 5.551746, T: 2705280, Avg. loss: 7.626218\n",
      "Total training time: 14.31 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 86.36, NNZs: 2821, Bias: 4.901018, T: 3043440, Avg. loss: 6.790038\n",
      "Total training time: 16.09 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 78.52, NNZs: 2821, Bias: 4.825830, T: 3381600, Avg. loss: 6.167901\n",
      "Total training time: 17.91 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 72.27, NNZs: 2821, Bias: 4.182254, T: 3719760, Avg. loss: 5.688981\n",
      "Total training time: 19.72 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 65.62, NNZs: 2821, Bias: 3.701643, T: 4057920, Avg. loss: 5.139972\n",
      "Total training time: 21.55 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 62.92, NNZs: 2821, Bias: 3.440272, T: 4396080, Avg. loss: 4.845286\n",
      "Total training time: 23.38 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58.43, NNZs: 2821, Bias: 3.211988, T: 4734240, Avg. loss: 4.607654\n",
      "Total training time: 25.22 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 55.08, NNZs: 2821, Bias: 2.926207, T: 5072400, Avg. loss: 4.292763\n",
      "Total training time: 27.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 51.92, NNZs: 2821, Bias: 2.738132, T: 5410560, Avg. loss: 4.047048\n",
      "Total training time: 28.92 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 48.67, NNZs: 2821, Bias: 2.552026, T: 5748720, Avg. loss: 3.842507\n",
      "Total training time: 30.81 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 46.07, NNZs: 2821, Bias: 2.316158, T: 6086880, Avg. loss: 3.669275\n",
      "Total training time: 32.79 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43.74, NNZs: 2821, Bias: 2.248292, T: 6425040, Avg. loss: 3.517486\n",
      "Total training time: 34.78 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41.33, NNZs: 2821, Bias: 2.124505, T: 6763200, Avg. loss: 3.376112\n",
      "Total training time: 36.70 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 39.44, NNZs: 2821, Bias: 1.766199, T: 7101360, Avg. loss: 3.227172\n",
      "Total training time: 38.56 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 37.78, NNZs: 2821, Bias: 1.799451, T: 7439520, Avg. loss: 3.121519\n",
      "Total training time: 40.44 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 35.97, NNZs: 2821, Bias: 1.795735, T: 7777680, Avg. loss: 3.004020\n",
      "Total training time: 42.31 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 35.09, NNZs: 2821, Bias: 1.659509, T: 8115840, Avg. loss: 2.859246\n",
      "Total training time: 44.18 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 33.27, NNZs: 2821, Bias: 1.735489, T: 8454000, Avg. loss: 2.824133\n",
      "Total training time: 46.06 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 32.40, NNZs: 2821, Bias: 1.576009, T: 8792160, Avg. loss: 2.726540\n",
      "Total training time: 47.93 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 31.23, NNZs: 2821, Bias: 1.415612, T: 9130320, Avg. loss: 2.655668\n",
      "Total training time: 49.81 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 29.98, NNZs: 2821, Bias: 1.362094, T: 9468480, Avg. loss: 2.592624\n",
      "Total training time: 51.67 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 28.97, NNZs: 2821, Bias: 1.227995, T: 9806640, Avg. loss: 2.502604\n",
      "Total training time: 53.55 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 28.14, NNZs: 2821, Bias: 1.252393, T: 10144800, Avg. loss: 2.440498\n",
      "Total training time: 55.43 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 27.67, NNZs: 2821, Bias: 1.295497, T: 10482960, Avg. loss: 2.387784\n",
      "Total training time: 57.32 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 26.87, NNZs: 2821, Bias: 1.140102, T: 10821120, Avg. loss: 2.333133\n",
      "Total training time: 59.64 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 25.92, NNZs: 2821, Bias: 0.992050, T: 11159280, Avg. loss: 2.328626\n",
      "Total training time: 62.05 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 24.99, NNZs: 2821, Bias: 1.102958, T: 11497440, Avg. loss: 2.243328\n",
      "Total training time: 63.99 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 24.24, NNZs: 2821, Bias: 1.036944, T: 11835600, Avg. loss: 2.167621\n",
      "Total training time: 65.90 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 23.61, NNZs: 2821, Bias: 1.042201, T: 12173760, Avg. loss: 2.146428\n",
      "Total training time: 67.86 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 23.21, NNZs: 2821, Bias: 0.930250, T: 12511920, Avg. loss: 2.107491\n",
      "Total training time: 69.78 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 22.90, NNZs: 2821, Bias: 0.938514, T: 12850080, Avg. loss: 2.065991\n",
      "Total training time: 71.72 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 22.09, NNZs: 2821, Bias: 0.913075, T: 13188240, Avg. loss: 2.043299\n",
      "Total training time: 73.66 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 21.89, NNZs: 2821, Bias: 0.764986, T: 13526400, Avg. loss: 2.010032\n",
      "Total training time: 75.60 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 21.31, NNZs: 2821, Bias: 0.788090, T: 13864560, Avg. loss: 1.973103\n",
      "Total training time: 77.53 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 20.80, NNZs: 2821, Bias: 0.836916, T: 14202720, Avg. loss: 1.948772\n",
      "Total training time: 79.48 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 20.22, NNZs: 2821, Bias: 0.792389, T: 14540880, Avg. loss: 1.925143\n",
      "Total training time: 81.40 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 19.95, NNZs: 2821, Bias: 0.731415, T: 14879040, Avg. loss: 1.879307\n",
      "Total training time: 83.33 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 19.67, NNZs: 2821, Bias: 0.720371, T: 15217200, Avg. loss: 1.856575\n",
      "Total training time: 85.79 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 19.20, NNZs: 2821, Bias: 0.620198, T: 15555360, Avg. loss: 1.847497\n",
      "Total training time: 88.11 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 18.81, NNZs: 2821, Bias: 0.755095, T: 15893520, Avg. loss: 1.810810\n",
      "Total training time: 90.04 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 18.44, NNZs: 2821, Bias: 0.628906, T: 16231680, Avg. loss: 1.788931\n",
      "Total training time: 91.99 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 18.08, NNZs: 2821, Bias: 0.615882, T: 16569840, Avg. loss: 1.762094\n",
      "Total training time: 93.96 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 17.74, NNZs: 2821, Bias: 0.626387, T: 16908000, Avg. loss: 1.723244\n",
      "Total training time: 95.91 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 17.52, NNZs: 2821, Bias: 0.672713, T: 17246160, Avg. loss: 1.717496\n",
      "Total training time: 97.86 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 17.28, NNZs: 2821, Bias: 0.564939, T: 17584320, Avg. loss: 1.696107\n",
      "Total training time: 99.80 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 17.06, NNZs: 2821, Bias: 0.538279, T: 17922480, Avg. loss: 1.672148\n",
      "Total training time: 101.78 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 16.85, NNZs: 2821, Bias: 0.553984, T: 18260640, Avg. loss: 1.661977\n",
      "Total training time: 103.74 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 16.31, NNZs: 2821, Bias: 0.491961, T: 18598800, Avg. loss: 1.663193\n",
      "Total training time: 105.67 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 16.07, NNZs: 2821, Bias: 0.584847, T: 18936960, Avg. loss: 1.631059\n",
      "Total training time: 107.60 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 15.71, NNZs: 2821, Bias: 0.575903, T: 19275120, Avg. loss: 1.602291\n",
      "Total training time: 109.66 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 15.38, NNZs: 2821, Bias: 0.537069, T: 19613280, Avg. loss: 1.585115\n",
      "Total training time: 112.21 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 15.44, NNZs: 2821, Bias: 0.532268, T: 19951440, Avg. loss: 1.567330\n",
      "Total training time: 114.36 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 15.24, NNZs: 2821, Bias: 0.491682, T: 20289600, Avg. loss: 1.576500\n",
      "Total training time: 116.29 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 14.96, NNZs: 2821, Bias: 0.422022, T: 20627760, Avg. loss: 1.549148\n",
      "Total training time: 118.29 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 14.74, NNZs: 2821, Bias: 0.414737, T: 20965920, Avg. loss: 1.550562\n",
      "Total training time: 120.26 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 14.55, NNZs: 2821, Bias: 0.432465, T: 21304080, Avg. loss: 1.524968\n",
      "Total training time: 122.24 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 14.23, NNZs: 2821, Bias: 0.441603, T: 21642240, Avg. loss: 1.516370\n",
      "Total training time: 124.21 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 13.91, NNZs: 2821, Bias: 0.416893, T: 21980400, Avg. loss: 1.498491\n",
      "Total training time: 126.18 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 13.76, NNZs: 2821, Bias: 0.446874, T: 22318560, Avg. loss: 1.472432\n",
      "Total training time: 128.16 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 13.53, NNZs: 2821, Bias: 0.338185, T: 22656720, Avg. loss: 1.457164\n",
      "Total training time: 130.13 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 13.42, NNZs: 2821, Bias: 0.429766, T: 22994880, Avg. loss: 1.458306\n",
      "Total training time: 132.08 seconds.\n",
      "-- Epoch 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.30, NNZs: 2821, Bias: 0.334912, T: 23333040, Avg. loss: 1.446481\n",
      "Total training time: 134.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 13.34, NNZs: 2821, Bias: 0.364839, T: 23671200, Avg. loss: 1.437437\n",
      "Total training time: 136.31 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 13.04, NNZs: 2821, Bias: 0.319904, T: 24009360, Avg. loss: 1.439032\n",
      "Total training time: 138.90 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 12.85, NNZs: 2821, Bias: 0.425113, T: 24347520, Avg. loss: 1.431874\n",
      "Total training time: 140.95 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 12.60, NNZs: 2821, Bias: 0.328720, T: 24685680, Avg. loss: 1.407047\n",
      "Total training time: 142.96 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 12.49, NNZs: 2821, Bias: 0.344698, T: 25023840, Avg. loss: 1.397943\n",
      "Total training time: 144.97 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 12.25, NNZs: 2821, Bias: 0.286192, T: 25362000, Avg. loss: 1.388411\n",
      "Total training time: 146.95 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 12.40, NNZs: 2821, Bias: 0.324801, T: 25700160, Avg. loss: 1.371707\n",
      "Total training time: 148.94 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 12.26, NNZs: 2821, Bias: 0.281679, T: 26038320, Avg. loss: 1.385394\n",
      "Total training time: 150.94 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 12.14, NNZs: 2821, Bias: 0.304353, T: 26376480, Avg. loss: 1.368704\n",
      "Total training time: 152.93 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 11.78, NNZs: 2821, Bias: 0.252230, T: 26714640, Avg. loss: 1.354001\n",
      "Total training time: 154.89 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 11.75, NNZs: 2821, Bias: 0.298934, T: 27052800, Avg. loss: 1.341654\n",
      "Total training time: 156.87 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 11.60, NNZs: 2821, Bias: 0.273576, T: 27390960, Avg. loss: 1.343598\n",
      "Total training time: 158.82 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 11.40, NNZs: 2821, Bias: 0.291293, T: 27729120, Avg. loss: 1.328392\n",
      "Total training time: 160.82 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 11.24, NNZs: 2821, Bias: 0.227351, T: 28067280, Avg. loss: 1.324730\n",
      "Total training time: 163.35 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 11.18, NNZs: 2821, Bias: 0.233276, T: 28405440, Avg. loss: 1.307397\n",
      "Total training time: 165.71 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 11.14, NNZs: 2821, Bias: 0.272575, T: 28743600, Avg. loss: 1.318677\n",
      "Total training time: 167.67 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 11.01, NNZs: 2821, Bias: 0.276166, T: 29081760, Avg. loss: 1.305634\n",
      "Total training time: 169.67 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 10.80, NNZs: 2821, Bias: 0.234530, T: 29419920, Avg. loss: 1.289943\n",
      "Total training time: 171.68 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 10.67, NNZs: 2821, Bias: 0.248818, T: 29758080, Avg. loss: 1.280012\n",
      "Total training time: 173.69 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 10.82, NNZs: 2821, Bias: 0.237326, T: 30096240, Avg. loss: 1.285155\n",
      "Total training time: 175.71 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 10.65, NNZs: 2821, Bias: 0.224443, T: 30434400, Avg. loss: 1.290854\n",
      "Total training time: 177.71 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 10.51, NNZs: 2821, Bias: 0.149840, T: 30772560, Avg. loss: 1.272489\n",
      "Total training time: 179.72 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 10.41, NNZs: 2821, Bias: 0.165815, T: 31110720, Avg. loss: 1.268733\n",
      "Total training time: 181.73 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 10.22, NNZs: 2821, Bias: 0.234057, T: 31448880, Avg. loss: 1.265063\n",
      "Total training time: 183.72 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 10.20, NNZs: 2821, Bias: 0.193489, T: 31787040, Avg. loss: 1.253684\n",
      "Total training time: 185.68 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 10.06, NNZs: 2821, Bias: 0.223818, T: 32125200, Avg. loss: 1.255109\n",
      "Total training time: 187.93 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 9.95, NNZs: 2821, Bias: 0.186780, T: 32463360, Avg. loss: 1.233853\n",
      "Total training time: 190.51 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 9.85, NNZs: 2821, Bias: 0.136223, T: 32801520, Avg. loss: 1.233454\n",
      "Total training time: 192.56 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 9.74, NNZs: 2821, Bias: 0.214103, T: 33139680, Avg. loss: 1.225551\n",
      "Total training time: 194.57 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 9.71, NNZs: 2821, Bias: 0.116060, T: 33477840, Avg. loss: 1.221445\n",
      "Total training time: 196.59 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 9.62, NNZs: 2821, Bias: 0.117597, T: 33816000, Avg. loss: 1.216026\n",
      "Total training time: 198.62 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 9.59, NNZs: 2821, Bias: 0.188513, T: 34154160, Avg. loss: 1.217069\n",
      "Total training time: 200.64 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 9.54, NNZs: 2821, Bias: 0.155998, T: 34492320, Avg. loss: 1.211811\n",
      "Total training time: 202.68 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 9.48, NNZs: 2821, Bias: 0.129084, T: 34830480, Avg. loss: 1.208503\n",
      "Total training time: 204.72 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 9.37, NNZs: 2821, Bias: 0.168867, T: 35168640, Avg. loss: 1.205560\n",
      "Total training time: 206.74 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 9.27, NNZs: 2821, Bias: 0.133817, T: 35506800, Avg. loss: 1.188134\n",
      "Total training time: 208.74 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 9.24, NNZs: 2821, Bias: 0.168960, T: 35844960, Avg. loss: 1.190614\n",
      "Total training time: 210.71 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 9.29, NNZs: 2821, Bias: 0.171944, T: 36183120, Avg. loss: 1.191023\n",
      "Total training time: 212.84 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 9.18, NNZs: 2821, Bias: 0.107033, T: 36521280, Avg. loss: 1.187097\n",
      "Total training time: 215.45 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 9.14, NNZs: 2821, Bias: 0.123404, T: 36859440, Avg. loss: 1.177566\n",
      "Total training time: 217.61 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 8.95, NNZs: 2821, Bias: 0.153280, T: 37197600, Avg. loss: 1.176622\n",
      "Total training time: 219.59 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 8.87, NNZs: 2821, Bias: 0.059275, T: 37535760, Avg. loss: 1.166274\n",
      "Total training time: 221.63 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 8.85, NNZs: 2821, Bias: 0.162433, T: 37873920, Avg. loss: 1.168643\n",
      "Total training time: 223.65 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 8.86, NNZs: 2821, Bias: 0.107446, T: 38212080, Avg. loss: 1.160203\n",
      "Total training time: 225.65 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 8.77, NNZs: 2821, Bias: 0.136476, T: 38550240, Avg. loss: 1.154825\n",
      "Total training time: 227.67 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 8.70, NNZs: 2821, Bias: 0.093500, T: 38888400, Avg. loss: 1.157422\n",
      "Total training time: 229.70 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 8.56, NNZs: 2821, Bias: 0.084066, T: 39226560, Avg. loss: 1.142506\n",
      "Total training time: 231.75 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 8.61, NNZs: 2821, Bias: 0.105259, T: 39564720, Avg. loss: 1.146895\n",
      "Total training time: 233.77 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 8.52, NNZs: 2821, Bias: 0.112856, T: 39902880, Avg. loss: 1.150828\n",
      "Total training time: 235.76 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 8.37, NNZs: 2821, Bias: 0.091346, T: 40241040, Avg. loss: 1.139155\n",
      "Total training time: 237.76 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 8.29, NNZs: 2821, Bias: 0.073475, T: 40579200, Avg. loss: 1.135543\n",
      "Total training time: 240.34 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 8.25, NNZs: 2821, Bias: 0.091966, T: 40917360, Avg. loss: 1.127171\n",
      "Total training time: 242.81 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 8.37, NNZs: 2821, Bias: 0.066927, T: 41255520, Avg. loss: 1.123095\n",
      "Total training time: 244.81 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 8.33, NNZs: 2821, Bias: 0.115783, T: 41593680, Avg. loss: 1.129658\n",
      "Total training time: 246.84 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 8.22, NNZs: 2821, Bias: 0.088455, T: 41931840, Avg. loss: 1.128788\n",
      "Total training time: 248.95 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 8.11, NNZs: 2821, Bias: 0.111616, T: 42270000, Avg. loss: 1.118087\n",
      "Total training time: 251.11 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 8.09, NNZs: 2821, Bias: 0.076318, T: 42608160, Avg. loss: 1.117964\n",
      "Total training time: 253.16 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 8.02, NNZs: 2821, Bias: 0.043567, T: 42946320, Avg. loss: 1.108377\n",
      "Total training time: 255.18 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 7.94, NNZs: 2821, Bias: 0.063292, T: 43284480, Avg. loss: 1.106276\n",
      "Total training time: 257.20 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 7.98, NNZs: 2821, Bias: 0.063077, T: 43622640, Avg. loss: 1.101304\n",
      "Total training time: 259.23 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 7.99, NNZs: 2821, Bias: 0.078522, T: 43960800, Avg. loss: 1.102359\n",
      "Total training time: 261.23 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 7.90, NNZs: 2821, Bias: 0.090732, T: 44298960, Avg. loss: 1.104319\n",
      "Total training time: 263.21 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 7.82, NNZs: 2821, Bias: 0.023027, T: 44637120, Avg. loss: 1.108045\n",
      "Total training time: 265.70 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 7.77, NNZs: 2821, Bias: 0.082745, T: 44975280, Avg. loss: 1.094227\n",
      "Total training time: 268.24 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 7.76, NNZs: 2821, Bias: 0.067711, T: 45313440, Avg. loss: 1.083668\n",
      "Total training time: 270.28 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 7.72, NNZs: 2821, Bias: 0.083878, T: 45651600, Avg. loss: 1.082804\n",
      "Total training time: 272.37 seconds.\n",
      "-- Epoch 136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 7.67, NNZs: 2821, Bias: 0.054241, T: 45989760, Avg. loss: 1.089687\n",
      "Total training time: 274.41 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 7.61, NNZs: 2821, Bias: 0.007579, T: 46327920, Avg. loss: 1.084300\n",
      "Total training time: 276.53 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 7.54, NNZs: 2821, Bias: 0.028249, T: 46666080, Avg. loss: 1.086508\n",
      "Total training time: 278.70 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 7.55, NNZs: 2821, Bias: 0.036073, T: 47004240, Avg. loss: 1.067346\n",
      "Total training time: 280.82 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 7.58, NNZs: 2821, Bias: 0.030342, T: 47342400, Avg. loss: 1.072400\n",
      "Total training time: 283.02 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 7.55, NNZs: 2821, Bias: 0.047304, T: 47680560, Avg. loss: 1.073983\n",
      "Total training time: 285.19 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 7.49, NNZs: 2821, Bias: 0.030670, T: 48018720, Avg. loss: 1.074484\n",
      "Total training time: 287.36 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 7.42, NNZs: 2821, Bias: 0.017413, T: 48356880, Avg. loss: 1.066570\n",
      "Total training time: 289.52 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 7.33, NNZs: 2821, Bias: 0.010362, T: 48695040, Avg. loss: 1.057752\n",
      "Total training time: 292.27 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 7.33, NNZs: 2821, Bias: 0.054720, T: 49033200, Avg. loss: 1.055180\n",
      "Total training time: 294.75 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 7.30, NNZs: 2821, Bias: 0.072477, T: 49371360, Avg. loss: 1.060194\n",
      "Total training time: 296.90 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 7.23, NNZs: 2821, Bias: 0.022958, T: 49709520, Avg. loss: 1.060108\n",
      "Total training time: 299.12 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 7.18, NNZs: 2821, Bias: 0.003221, T: 50047680, Avg. loss: 1.055704\n",
      "Total training time: 301.28 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 7.20, NNZs: 2821, Bias: 0.048692, T: 50385840, Avg. loss: 1.053323\n",
      "Total training time: 303.49 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 7.18, NNZs: 2821, Bias: -0.000059, T: 50724000, Avg. loss: 1.045458\n",
      "Total training time: 305.63 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 7.17, NNZs: 2821, Bias: 0.050010, T: 51062160, Avg. loss: 1.048073\n",
      "Total training time: 307.83 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 7.11, NNZs: 2821, Bias: 0.020407, T: 51400320, Avg. loss: 1.045240\n",
      "Total training time: 310.00 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 7.12, NNZs: 2821, Bias: 0.020593, T: 51738480, Avg. loss: 1.049312\n",
      "Total training time: 312.17 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 7.11, NNZs: 2821, Bias: 0.029583, T: 52076640, Avg. loss: 1.043001\n",
      "Total training time: 314.34 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 7.06, NNZs: 2821, Bias: 0.037183, T: 52414800, Avg. loss: 1.042182\n",
      "Total training time: 316.78 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 6.96, NNZs: 2821, Bias: 0.006219, T: 52752960, Avg. loss: 1.041943\n",
      "Total training time: 319.63 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 7.00, NNZs: 2821, Bias: 0.002690, T: 53091120, Avg. loss: 1.032191\n",
      "Total training time: 321.84 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 6.96, NNZs: 2821, Bias: 0.017919, T: 53429280, Avg. loss: 1.034097\n",
      "Total training time: 324.04 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 6.98, NNZs: 2821, Bias: -0.016203, T: 53767440, Avg. loss: 1.033786\n",
      "Total training time: 326.26 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 6.95, NNZs: 2821, Bias: 0.023079, T: 54105600, Avg. loss: 1.028296\n",
      "Total training time: 328.46 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 6.92, NNZs: 2821, Bias: 0.001066, T: 54443760, Avg. loss: 1.027219\n",
      "Total training time: 330.65 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 6.87, NNZs: 2821, Bias: 0.007169, T: 54781920, Avg. loss: 1.025815\n",
      "Total training time: 332.85 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 6.84, NNZs: 2821, Bias: 0.045095, T: 55120080, Avg. loss: 1.026043\n",
      "Total training time: 335.05 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 6.82, NNZs: 2821, Bias: 0.036064, T: 55458240, Avg. loss: 1.017829\n",
      "Total training time: 337.24 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 6.76, NNZs: 2821, Bias: 0.012073, T: 55796400, Avg. loss: 1.019781\n",
      "Total training time: 339.39 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 6.75, NNZs: 2821, Bias: 0.038568, T: 56134560, Avg. loss: 1.015214\n",
      "Total training time: 341.63 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 6.84, NNZs: 2821, Bias: -0.015444, T: 56472720, Avg. loss: 1.010128\n",
      "Total training time: 344.48 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 6.87, NNZs: 2821, Bias: 0.009464, T: 56810880, Avg. loss: 1.016236\n",
      "Total training time: 346.91 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 6.80, NNZs: 2821, Bias: -0.007936, T: 57149040, Avg. loss: 1.014206\n",
      "Total training time: 349.12 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 6.77, NNZs: 2821, Bias: 0.016944, T: 57487200, Avg. loss: 1.017265\n",
      "Total training time: 351.36 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 6.67, NNZs: 2821, Bias: 0.005459, T: 57825360, Avg. loss: 1.008578\n",
      "Total training time: 353.58 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 6.59, NNZs: 2821, Bias: 0.012078, T: 58163520, Avg. loss: 1.007447\n",
      "Total training time: 355.78 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 6.58, NNZs: 2821, Bias: -0.006072, T: 58501680, Avg. loss: 1.001472\n",
      "Total training time: 357.97 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 6.55, NNZs: 2821, Bias: -0.004576, T: 58839840, Avg. loss: 1.003824\n",
      "Total training time: 360.16 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 6.54, NNZs: 2821, Bias: -0.014987, T: 59178000, Avg. loss: 1.000793\n",
      "Total training time: 362.38 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 6.57, NNZs: 2821, Bias: 0.021367, T: 59516160, Avg. loss: 0.996994\n",
      "Total training time: 364.56 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 6.55, NNZs: 2821, Bias: 0.040805, T: 59854320, Avg. loss: 1.004053\n",
      "Total training time: 366.76 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 6.47, NNZs: 2821, Bias: 0.004949, T: 60192480, Avg. loss: 1.000930\n",
      "Total training time: 369.46 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 6.43, NNZs: 2821, Bias: -0.020322, T: 60530640, Avg. loss: 0.988906\n",
      "Total training time: 372.11 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 6.49, NNZs: 2821, Bias: 0.031810, T: 60868800, Avg. loss: 0.990601\n",
      "Total training time: 374.29 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 6.46, NNZs: 2821, Bias: 0.003870, T: 61206960, Avg. loss: 0.996262\n",
      "Total training time: 376.52 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 6.45, NNZs: 2821, Bias: 0.001359, T: 61545120, Avg. loss: 0.990489\n",
      "Total training time: 378.74 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 6.38, NNZs: 2821, Bias: -0.030871, T: 61883280, Avg. loss: 0.990591\n",
      "Total training time: 380.95 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 6.34, NNZs: 2821, Bias: -0.035585, T: 62221440, Avg. loss: 0.983308\n",
      "Total training time: 383.19 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 6.29, NNZs: 2821, Bias: -0.010319, T: 62559600, Avg. loss: 0.983661\n",
      "Total training time: 385.40 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 6.24, NNZs: 2821, Bias: -0.049838, T: 62897760, Avg. loss: 0.988026\n",
      "Total training time: 387.62 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 6.24, NNZs: 2821, Bias: -0.014363, T: 63235920, Avg. loss: 0.982898\n",
      "Total training time: 389.81 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 6.21, NNZs: 2821, Bias: -0.030397, T: 63574080, Avg. loss: 0.983856\n",
      "Total training time: 391.97 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 6.20, NNZs: 2821, Bias: -0.027718, T: 63912240, Avg. loss: 0.986437\n",
      "Total training time: 394.45 seconds.\n",
      "Convergence after 189 epochs took 394.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 711.16, NNZs: 2821, Bias: 49.306154, T: 338160, Avg. loss: 187.182844\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 406.36, NNZs: 2821, Bias: 26.866332, T: 676320, Avg. loss: 38.182320\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 265.08, NNZs: 2821, Bias: 18.369181, T: 1014480, Avg. loss: 22.481991\n",
      "Total training time: 5.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 196.81, NNZs: 2821, Bias: 12.201078, T: 1352640, Avg. loss: 16.014762\n",
      "Total training time: 7.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 153.50, NNZs: 2821, Bias: 9.080816, T: 1690800, Avg. loss: 12.283670\n",
      "Total training time: 8.76 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 128.30, NNZs: 2821, Bias: 7.704496, T: 2028960, Avg. loss: 10.031001\n",
      "Total training time: 10.53 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 114.02, NNZs: 2821, Bias: 6.445504, T: 2367120, Avg. loss: 8.495916\n",
      "Total training time: 12.31 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 101.60, NNZs: 2821, Bias: 5.426017, T: 2705280, Avg. loss: 7.581177\n",
      "Total training time: 14.10 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 91.99, NNZs: 2821, Bias: 5.510785, T: 3043440, Avg. loss: 6.754815\n",
      "Total training time: 15.89 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 84.56, NNZs: 2821, Bias: 4.651079, T: 3381600, Avg. loss: 6.133320\n",
      "Total training time: 17.68 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 77.47, NNZs: 2821, Bias: 4.374939, T: 3719760, Avg. loss: 5.650381\n",
      "Total training time: 19.48 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 71.56, NNZs: 2821, Bias: 4.052752, T: 4057920, Avg. loss: 5.195433\n",
      "Total training time: 21.27 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 65.85, NNZs: 2821, Bias: 3.583624, T: 4396080, Avg. loss: 4.858009\n",
      "Total training time: 23.10 seconds.\n",
      "-- Epoch 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 61.74, NNZs: 2821, Bias: 3.638984, T: 4734240, Avg. loss: 4.505544\n",
      "Total training time: 25.36 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 57.33, NNZs: 2821, Bias: 2.979402, T: 5072400, Avg. loss: 4.253581\n",
      "Total training time: 27.67 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 53.61, NNZs: 2821, Bias: 2.758193, T: 5410560, Avg. loss: 4.018119\n",
      "Total training time: 29.52 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 50.56, NNZs: 2821, Bias: 2.622007, T: 5748720, Avg. loss: 3.782858\n",
      "Total training time: 31.35 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47.98, NNZs: 2821, Bias: 2.130572, T: 6086880, Avg. loss: 3.652208\n",
      "Total training time: 33.17 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 46.19, NNZs: 2821, Bias: 2.401489, T: 6425040, Avg. loss: 3.502360\n",
      "Total training time: 35.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.84, NNZs: 2821, Bias: 2.231207, T: 6763200, Avg. loss: 3.334449\n",
      "Total training time: 36.85 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 42.11, NNZs: 2821, Bias: 2.103176, T: 7101360, Avg. loss: 3.183245\n",
      "Total training time: 38.70 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 40.13, NNZs: 2821, Bias: 2.017533, T: 7439520, Avg. loss: 3.103992\n",
      "Total training time: 40.56 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 38.25, NNZs: 2821, Bias: 1.912464, T: 7777680, Avg. loss: 2.978516\n",
      "Total training time: 42.44 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 36.36, NNZs: 2821, Bias: 1.711996, T: 8115840, Avg. loss: 2.881470\n",
      "Total training time: 44.30 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 35.17, NNZs: 2821, Bias: 1.675588, T: 8454000, Avg. loss: 2.785766\n",
      "Total training time: 46.21 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 34.07, NNZs: 2821, Bias: 1.715723, T: 8792160, Avg. loss: 2.704340\n",
      "Total training time: 48.10 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 32.72, NNZs: 2821, Bias: 1.546874, T: 9130320, Avg. loss: 2.620624\n",
      "Total training time: 49.99 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 31.86, NNZs: 2821, Bias: 1.547715, T: 9468480, Avg. loss: 2.532252\n",
      "Total training time: 51.88 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 31.50, NNZs: 2821, Bias: 1.515114, T: 9806640, Avg. loss: 2.490725\n",
      "Total training time: 53.81 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 30.37, NNZs: 2821, Bias: 1.472451, T: 10144800, Avg. loss: 2.448192\n",
      "Total training time: 55.70 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 29.40, NNZs: 2821, Bias: 1.421142, T: 10482960, Avg. loss: 2.373863\n",
      "Total training time: 57.61 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 28.06, NNZs: 2821, Bias: 1.301029, T: 10821120, Avg. loss: 2.329177\n",
      "Total training time: 59.69 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 27.26, NNZs: 2821, Bias: 1.233032, T: 11159280, Avg. loss: 2.277372\n",
      "Total training time: 62.19 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 26.35, NNZs: 2821, Bias: 1.219154, T: 11497440, Avg. loss: 2.216187\n",
      "Total training time: 64.21 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 25.60, NNZs: 2821, Bias: 1.120875, T: 11835600, Avg. loss: 2.177705\n",
      "Total training time: 66.13 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 25.20, NNZs: 2821, Bias: 1.038459, T: 12173760, Avg. loss: 2.134599\n",
      "Total training time: 68.05 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 24.70, NNZs: 2821, Bias: 1.020307, T: 12511920, Avg. loss: 2.101949\n",
      "Total training time: 69.98 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 24.21, NNZs: 2821, Bias: 0.997559, T: 12850080, Avg. loss: 2.072050\n",
      "Total training time: 71.88 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 23.46, NNZs: 2821, Bias: 1.043406, T: 13188240, Avg. loss: 2.035998\n",
      "Total training time: 73.81 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 22.79, NNZs: 2821, Bias: 0.977215, T: 13526400, Avg. loss: 2.019370\n",
      "Total training time: 75.73 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 22.37, NNZs: 2821, Bias: 0.933943, T: 13864560, Avg. loss: 1.963961\n",
      "Total training time: 77.67 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 21.99, NNZs: 2821, Bias: 1.012356, T: 14202720, Avg. loss: 1.928172\n",
      "Total training time: 79.59 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 21.35, NNZs: 2821, Bias: 0.856019, T: 14540880, Avg. loss: 1.921470\n",
      "Total training time: 81.49 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 20.85, NNZs: 2821, Bias: 0.910906, T: 14879040, Avg. loss: 1.866608\n",
      "Total training time: 83.39 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 20.46, NNZs: 2821, Bias: 0.866035, T: 15217200, Avg. loss: 1.835222\n",
      "Total training time: 85.53 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 20.25, NNZs: 2821, Bias: 0.755829, T: 15555360, Avg. loss: 1.813466\n",
      "Total training time: 88.04 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 19.99, NNZs: 2821, Bias: 0.883705, T: 15893520, Avg. loss: 1.790662\n",
      "Total training time: 90.05 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 19.50, NNZs: 2821, Bias: 0.676966, T: 16231680, Avg. loss: 1.772376\n",
      "Total training time: 91.99 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 19.03, NNZs: 2821, Bias: 0.749830, T: 16569840, Avg. loss: 1.753224\n",
      "Total training time: 93.92 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 18.84, NNZs: 2821, Bias: 0.759277, T: 16908000, Avg. loss: 1.734046\n",
      "Total training time: 95.87 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 18.36, NNZs: 2821, Bias: 0.736408, T: 17246160, Avg. loss: 1.721822\n",
      "Total training time: 97.83 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 18.05, NNZs: 2821, Bias: 0.714198, T: 17584320, Avg. loss: 1.694863\n",
      "Total training time: 99.75 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 17.60, NNZs: 2821, Bias: 0.606205, T: 17922480, Avg. loss: 1.670089\n",
      "Total training time: 101.71 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 17.30, NNZs: 2821, Bias: 0.703577, T: 18260640, Avg. loss: 1.651605\n",
      "Total training time: 103.66 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 17.30, NNZs: 2821, Bias: 0.612574, T: 18598800, Avg. loss: 1.624205\n",
      "Total training time: 105.61 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 17.07, NNZs: 2821, Bias: 0.661943, T: 18936960, Avg. loss: 1.624278\n",
      "Total training time: 107.51 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 16.74, NNZs: 2821, Bias: 0.617408, T: 19275120, Avg. loss: 1.615220\n",
      "Total training time: 109.45 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 16.40, NNZs: 2821, Bias: 0.534483, T: 19613280, Avg. loss: 1.588301\n",
      "Total training time: 111.82 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 16.09, NNZs: 2821, Bias: 0.570173, T: 19951440, Avg. loss: 1.576987\n",
      "Total training time: 114.22 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 15.86, NNZs: 2821, Bias: 0.560757, T: 20289600, Avg. loss: 1.566685\n",
      "Total training time: 116.17 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 15.55, NNZs: 2821, Bias: 0.560493, T: 20627760, Avg. loss: 1.542428\n",
      "Total training time: 118.14 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 15.14, NNZs: 2821, Bias: 0.469430, T: 20965920, Avg. loss: 1.534182\n",
      "Total training time: 120.10 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 15.29, NNZs: 2821, Bias: 0.536319, T: 21304080, Avg. loss: 1.502843\n",
      "Total training time: 122.08 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 15.09, NNZs: 2821, Bias: 0.460270, T: 21642240, Avg. loss: 1.495562\n",
      "Total training time: 124.05 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 14.95, NNZs: 2821, Bias: 0.455244, T: 21980400, Avg. loss: 1.494143\n",
      "Total training time: 126.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 14.59, NNZs: 2821, Bias: 0.414883, T: 22318560, Avg. loss: 1.478763\n",
      "Total training time: 127.98 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 14.37, NNZs: 2821, Bias: 0.421567, T: 22656720, Avg. loss: 1.466154\n",
      "Total training time: 129.98 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 14.15, NNZs: 2821, Bias: 0.414354, T: 22994880, Avg. loss: 1.451333\n",
      "Total training time: 131.95 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 13.85, NNZs: 2821, Bias: 0.388666, T: 23333040, Avg. loss: 1.447635\n",
      "Total training time: 133.87 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 13.71, NNZs: 2821, Bias: 0.466242, T: 23671200, Avg. loss: 1.429586\n",
      "Total training time: 135.92 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 13.46, NNZs: 2821, Bias: 0.436655, T: 24009360, Avg. loss: 1.416895\n",
      "Total training time: 138.48 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 13.31, NNZs: 2821, Bias: 0.448465, T: 24347520, Avg. loss: 1.408352\n",
      "Total training time: 140.66 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 13.24, NNZs: 2821, Bias: 0.364928, T: 24685680, Avg. loss: 1.404637\n",
      "Total training time: 142.62 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 13.17, NNZs: 2821, Bias: 0.367912, T: 25023840, Avg. loss: 1.405016\n",
      "Total training time: 144.61 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 12.91, NNZs: 2821, Bias: 0.378681, T: 25362000, Avg. loss: 1.383304\n",
      "Total training time: 146.59 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 12.82, NNZs: 2821, Bias: 0.367019, T: 25700160, Avg. loss: 1.376450\n",
      "Total training time: 148.58 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 12.55, NNZs: 2821, Bias: 0.385773, T: 26038320, Avg. loss: 1.362173\n",
      "Total training time: 150.55 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 12.40, NNZs: 2821, Bias: 0.322213, T: 26376480, Avg. loss: 1.358846\n",
      "Total training time: 152.52 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 12.17, NNZs: 2821, Bias: 0.377579, T: 26714640, Avg. loss: 1.344810\n",
      "Total training time: 154.58 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 12.07, NNZs: 2821, Bias: 0.261275, T: 27052800, Avg. loss: 1.335126\n",
      "Total training time: 156.65 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 12.06, NNZs: 2821, Bias: 0.277269, T: 27390960, Avg. loss: 1.331236\n",
      "Total training time: 158.61 seconds.\n",
      "-- Epoch 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 11.96, NNZs: 2821, Bias: 0.279289, T: 27729120, Avg. loss: 1.325708\n",
      "Total training time: 160.57 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 11.96, NNZs: 2821, Bias: 0.306727, T: 28067280, Avg. loss: 1.323961\n",
      "Total training time: 163.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 11.79, NNZs: 2821, Bias: 0.287934, T: 28405440, Avg. loss: 1.311401\n",
      "Total training time: 165.41 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 11.74, NNZs: 2821, Bias: 0.292895, T: 28743600, Avg. loss: 1.317502\n",
      "Total training time: 167.37 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 11.56, NNZs: 2821, Bias: 0.339328, T: 29081760, Avg. loss: 1.298275\n",
      "Total training time: 169.37 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 11.35, NNZs: 2821, Bias: 0.251576, T: 29419920, Avg. loss: 1.294140\n",
      "Total training time: 171.36 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 11.25, NNZs: 2821, Bias: 0.239940, T: 29758080, Avg. loss: 1.282011\n",
      "Total training time: 173.34 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 11.28, NNZs: 2821, Bias: 0.275125, T: 30096240, Avg. loss: 1.273794\n",
      "Total training time: 175.35 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 11.16, NNZs: 2821, Bias: 0.359949, T: 30434400, Avg. loss: 1.277763\n",
      "Total training time: 177.36 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 10.96, NNZs: 2821, Bias: 0.216717, T: 30772560, Avg. loss: 1.279815\n",
      "Total training time: 179.35 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 10.91, NNZs: 2821, Bias: 0.289704, T: 31110720, Avg. loss: 1.258514\n",
      "Total training time: 181.34 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 10.78, NNZs: 2821, Bias: 0.201038, T: 31448880, Avg. loss: 1.261166\n",
      "Total training time: 183.33 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 10.69, NNZs: 2821, Bias: 0.229113, T: 31787040, Avg. loss: 1.240695\n",
      "Total training time: 185.30 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 10.57, NNZs: 2821, Bias: 0.255017, T: 32125200, Avg. loss: 1.247428\n",
      "Total training time: 187.48 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 10.41, NNZs: 2821, Bias: 0.244916, T: 32463360, Avg. loss: 1.238967\n",
      "Total training time: 190.10 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 10.46, NNZs: 2821, Bias: 0.227483, T: 32801520, Avg. loss: 1.225719\n",
      "Total training time: 192.20 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 10.40, NNZs: 2821, Bias: 0.246780, T: 33139680, Avg. loss: 1.222446\n",
      "Total training time: 194.18 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 10.32, NNZs: 2821, Bias: 0.239622, T: 33477840, Avg. loss: 1.227414\n",
      "Total training time: 196.21 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 10.24, NNZs: 2821, Bias: 0.187757, T: 33816000, Avg. loss: 1.216358\n",
      "Total training time: 198.20 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 10.13, NNZs: 2821, Bias: 0.226918, T: 34154160, Avg. loss: 1.215208\n",
      "Total training time: 200.19 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 10.04, NNZs: 2821, Bias: 0.235902, T: 34492320, Avg. loss: 1.208199\n",
      "Total training time: 202.18 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 9.90, NNZs: 2821, Bias: 0.215066, T: 34830480, Avg. loss: 1.202948\n",
      "Total training time: 204.18 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 9.84, NNZs: 2821, Bias: 0.201782, T: 35168640, Avg. loss: 1.196737\n",
      "Total training time: 206.19 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 9.75, NNZs: 2821, Bias: 0.157871, T: 35506800, Avg. loss: 1.182454\n",
      "Total training time: 208.18 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 9.69, NNZs: 2821, Bias: 0.158631, T: 35844960, Avg. loss: 1.192306\n",
      "Total training time: 210.15 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 9.59, NNZs: 2821, Bias: 0.171283, T: 36183120, Avg. loss: 1.178600\n",
      "Total training time: 212.19 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 9.49, NNZs: 2821, Bias: 0.172392, T: 36521280, Avg. loss: 1.180372\n",
      "Total training time: 214.76 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 9.49, NNZs: 2821, Bias: 0.168547, T: 36859440, Avg. loss: 1.166520\n",
      "Total training time: 217.02 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 9.37, NNZs: 2821, Bias: 0.185035, T: 37197600, Avg. loss: 1.179685\n",
      "Total training time: 218.99 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 9.22, NNZs: 2821, Bias: 0.171456, T: 37535760, Avg. loss: 1.162645\n",
      "Total training time: 221.02 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 9.27, NNZs: 2821, Bias: 0.176187, T: 37873920, Avg. loss: 1.159513\n",
      "Total training time: 223.03 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 9.17, NNZs: 2821, Bias: 0.163252, T: 38212080, Avg. loss: 1.158931\n",
      "Total training time: 225.04 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 9.10, NNZs: 2821, Bias: 0.110649, T: 38550240, Avg. loss: 1.156800\n",
      "Total training time: 227.03 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 9.02, NNZs: 2821, Bias: 0.177547, T: 38888400, Avg. loss: 1.151207\n",
      "Total training time: 229.12 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 9.02, NNZs: 2821, Bias: 0.176194, T: 39226560, Avg. loss: 1.145205\n",
      "Total training time: 231.13 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 8.87, NNZs: 2821, Bias: 0.138231, T: 39564720, Avg. loss: 1.154125\n",
      "Total training time: 233.13 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 8.80, NNZs: 2821, Bias: 0.152009, T: 39902880, Avg. loss: 1.133259\n",
      "Total training time: 235.13 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 8.79, NNZs: 2821, Bias: 0.126440, T: 40241040, Avg. loss: 1.132551\n",
      "Total training time: 237.12 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 8.80, NNZs: 2821, Bias: 0.172035, T: 40579200, Avg. loss: 1.134680\n",
      "Total training time: 239.60 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 8.78, NNZs: 2821, Bias: 0.159068, T: 40917360, Avg. loss: 1.128884\n",
      "Total training time: 242.00 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 8.62, NNZs: 2821, Bias: 0.104494, T: 41255520, Avg. loss: 1.124274\n",
      "Total training time: 244.00 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 8.66, NNZs: 2821, Bias: 0.150274, T: 41593680, Avg. loss: 1.116672\n",
      "Total training time: 246.02 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 8.54, NNZs: 2821, Bias: 0.117600, T: 41931840, Avg. loss: 1.115706\n",
      "Total training time: 248.04 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 8.48, NNZs: 2821, Bias: 0.117742, T: 42270000, Avg. loss: 1.121367\n",
      "Total training time: 250.07 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 8.38, NNZs: 2821, Bias: 0.079052, T: 42608160, Avg. loss: 1.110355\n",
      "Total training time: 252.07 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 8.44, NNZs: 2821, Bias: 0.130565, T: 42946320, Avg. loss: 1.107838\n",
      "Total training time: 254.09 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 8.42, NNZs: 2821, Bias: 0.104430, T: 43284480, Avg. loss: 1.106343\n",
      "Total training time: 256.11 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 8.36, NNZs: 2821, Bias: 0.109109, T: 43622640, Avg. loss: 1.101762\n",
      "Total training time: 258.10 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 8.29, NNZs: 2821, Bias: 0.083982, T: 43960800, Avg. loss: 1.110036\n",
      "Total training time: 260.09 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 8.11, NNZs: 2821, Bias: 0.092674, T: 44298960, Avg. loss: 1.095515\n",
      "Total training time: 262.08 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 8.08, NNZs: 2821, Bias: 0.067458, T: 44637120, Avg. loss: 1.091791\n",
      "Total training time: 264.40 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 8.06, NNZs: 2821, Bias: 0.078718, T: 44975280, Avg. loss: 1.084123\n",
      "Total training time: 266.95 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 8.04, NNZs: 2821, Bias: 0.051955, T: 45313440, Avg. loss: 1.077975\n",
      "Total training time: 268.99 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 8.09, NNZs: 2821, Bias: 0.065768, T: 45651600, Avg. loss: 1.076830\n",
      "Total training time: 271.02 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 8.03, NNZs: 2821, Bias: 0.104624, T: 45989760, Avg. loss: 1.085216\n",
      "Total training time: 273.03 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 7.90, NNZs: 2821, Bias: 0.042474, T: 46327920, Avg. loss: 1.077852\n",
      "Total training time: 275.07 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 7.87, NNZs: 2821, Bias: 0.101542, T: 46666080, Avg. loss: 1.072979\n",
      "Total training time: 277.08 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 7.84, NNZs: 2821, Bias: 0.073664, T: 47004240, Avg. loss: 1.072006\n",
      "Total training time: 279.10 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 7.73, NNZs: 2821, Bias: 0.074345, T: 47342400, Avg. loss: 1.071507\n",
      "Total training time: 281.12 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 7.68, NNZs: 2821, Bias: 0.093011, T: 47680560, Avg. loss: 1.062761\n",
      "Total training time: 283.13 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 7.66, NNZs: 2821, Bias: 0.079990, T: 48018720, Avg. loss: 1.061792\n",
      "Total training time: 285.13 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 7.68, NNZs: 2821, Bias: 0.091170, T: 48356880, Avg. loss: 1.062609\n",
      "Total training time: 287.11 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 7.66, NNZs: 2821, Bias: 0.081229, T: 48695040, Avg. loss: 1.067648\n",
      "Total training time: 289.27 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 7.59, NNZs: 2821, Bias: 0.041202, T: 49033200, Avg. loss: 1.061419\n",
      "Total training time: 291.90 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 7.56, NNZs: 2821, Bias: 0.086391, T: 49371360, Avg. loss: 1.061509\n",
      "Total training time: 294.04 seconds.\n",
      "Convergence after 146 epochs took 294.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 712.80, NNZs: 2821, Bias: 51.454171, T: 338160, Avg. loss: 191.132224\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 391.41, NNZs: 2821, Bias: 28.518501, T: 676320, Avg. loss: 38.481871\n",
      "Total training time: 3.52 seconds.\n",
      "-- Epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 262.23, NNZs: 2821, Bias: 16.719232, T: 1014480, Avg. loss: 22.592377\n",
      "Total training time: 5.28 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 193.32, NNZs: 2821, Bias: 12.462147, T: 1352640, Avg. loss: 15.863026\n",
      "Total training time: 7.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 157.09, NNZs: 2821, Bias: 9.614282, T: 1690800, Avg. loss: 12.168015\n",
      "Total training time: 8.84 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 131.85, NNZs: 2821, Bias: 7.668883, T: 2028960, Avg. loss: 9.863567\n",
      "Total training time: 10.64 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 115.49, NNZs: 2821, Bias: 6.556457, T: 2367120, Avg. loss: 8.527280\n",
      "Total training time: 12.43 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 102.55, NNZs: 2821, Bias: 6.288954, T: 2705280, Avg. loss: 7.556575\n",
      "Total training time: 14.23 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 92.96, NNZs: 2821, Bias: 5.036031, T: 3043440, Avg. loss: 6.765219\n",
      "Total training time: 16.22 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 83.77, NNZs: 2821, Bias: 4.530820, T: 3381600, Avg. loss: 6.078408\n",
      "Total training time: 18.62 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 77.89, NNZs: 2821, Bias: 4.504186, T: 3719760, Avg. loss: 5.555813\n",
      "Total training time: 20.64 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 73.41, NNZs: 2821, Bias: 4.111003, T: 4057920, Avg. loss: 5.183614\n",
      "Total training time: 22.52 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 67.13, NNZs: 2821, Bias: 3.376541, T: 4396080, Avg. loss: 4.837922\n",
      "Total training time: 24.33 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 63.09, NNZs: 2821, Bias: 3.789499, T: 4734240, Avg. loss: 4.438975\n",
      "Total training time: 26.13 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 58.60, NNZs: 2821, Bias: 3.072476, T: 5072400, Avg. loss: 4.305290\n",
      "Total training time: 27.98 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 55.14, NNZs: 2821, Bias: 2.893837, T: 5410560, Avg. loss: 4.040328\n",
      "Total training time: 29.82 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 51.72, NNZs: 2821, Bias: 2.619154, T: 5748720, Avg. loss: 3.763353\n",
      "Total training time: 31.70 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 49.17, NNZs: 2821, Bias: 2.326383, T: 6086880, Avg. loss: 3.607478\n",
      "Total training time: 33.55 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 46.39, NNZs: 2821, Bias: 2.184887, T: 6425040, Avg. loss: 3.466805\n",
      "Total training time: 35.41 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.97, NNZs: 2821, Bias: 2.001554, T: 6763200, Avg. loss: 3.300876\n",
      "Total training time: 37.25 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 43.13, NNZs: 2821, Bias: 2.166150, T: 7101360, Avg. loss: 3.168289\n",
      "Total training time: 39.17 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 40.80, NNZs: 2821, Bias: 1.860661, T: 7439520, Avg. loss: 3.067651\n",
      "Total training time: 41.15 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 39.57, NNZs: 2821, Bias: 1.866076, T: 7777680, Avg. loss: 2.965819\n",
      "Total training time: 43.09 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 38.24, NNZs: 2821, Bias: 1.887490, T: 8115840, Avg. loss: 2.897893\n",
      "Total training time: 44.98 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 36.41, NNZs: 2821, Bias: 1.742856, T: 8454000, Avg. loss: 2.801949\n",
      "Total training time: 47.08 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 34.84, NNZs: 2821, Bias: 1.559624, T: 8792160, Avg. loss: 2.707949\n",
      "Total training time: 49.57 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 33.43, NNZs: 2821, Bias: 1.659212, T: 9130320, Avg. loss: 2.628710\n",
      "Total training time: 51.63 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 32.43, NNZs: 2821, Bias: 1.555585, T: 9468480, Avg. loss: 2.539575\n",
      "Total training time: 53.52 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 31.25, NNZs: 2821, Bias: 1.426450, T: 9806640, Avg. loss: 2.486700\n",
      "Total training time: 55.43 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 30.09, NNZs: 2821, Bias: 1.303664, T: 10144800, Avg. loss: 2.423360\n",
      "Total training time: 57.32 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 29.58, NNZs: 2821, Bias: 1.307565, T: 10482960, Avg. loss: 2.359413\n",
      "Total training time: 59.25 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 28.74, NNZs: 2821, Bias: 1.322638, T: 10821120, Avg. loss: 2.346504\n",
      "Total training time: 61.15 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 27.73, NNZs: 2821, Bias: 1.140954, T: 11159280, Avg. loss: 2.256230\n",
      "Total training time: 63.06 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 27.13, NNZs: 2821, Bias: 1.218118, T: 11497440, Avg. loss: 2.217186\n",
      "Total training time: 64.94 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 26.73, NNZs: 2821, Bias: 1.194896, T: 11835600, Avg. loss: 2.188045\n",
      "Total training time: 66.86 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 25.98, NNZs: 2821, Bias: 1.120208, T: 12173760, Avg. loss: 2.156479\n",
      "Total training time: 68.76 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 25.00, NNZs: 2821, Bias: 1.133337, T: 12511920, Avg. loss: 2.101773\n",
      "Total training time: 70.64 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 24.36, NNZs: 2821, Bias: 0.951224, T: 12850080, Avg. loss: 2.066773\n",
      "Total training time: 72.68 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 23.56, NNZs: 2821, Bias: 0.863518, T: 13188240, Avg. loss: 2.028579\n",
      "Total training time: 75.18 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 23.15, NNZs: 2821, Bias: 0.880104, T: 13526400, Avg. loss: 1.981165\n",
      "Total training time: 77.29 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 22.79, NNZs: 2821, Bias: 0.971182, T: 13864560, Avg. loss: 1.954624\n",
      "Total training time: 79.18 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 22.52, NNZs: 2821, Bias: 0.950723, T: 14202720, Avg. loss: 1.928736\n",
      "Total training time: 81.14 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 21.97, NNZs: 2821, Bias: 0.888381, T: 14540880, Avg. loss: 1.906267\n",
      "Total training time: 83.09 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 21.55, NNZs: 2821, Bias: 0.960951, T: 14879040, Avg. loss: 1.885669\n",
      "Total training time: 85.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 20.84, NNZs: 2821, Bias: 0.760403, T: 15217200, Avg. loss: 1.869939\n",
      "Total training time: 86.97 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 20.21, NNZs: 2821, Bias: 0.833759, T: 15555360, Avg. loss: 1.826818\n",
      "Total training time: 88.90 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 19.71, NNZs: 2821, Bias: 0.702319, T: 15893520, Avg. loss: 1.793292\n",
      "Total training time: 90.84 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 19.37, NNZs: 2821, Bias: 0.679396, T: 16231680, Avg. loss: 1.758709\n",
      "Total training time: 92.80 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 19.13, NNZs: 2821, Bias: 0.689152, T: 16569840, Avg. loss: 1.751414\n",
      "Total training time: 94.72 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 18.90, NNZs: 2821, Bias: 0.700055, T: 16908000, Avg. loss: 1.725064\n",
      "Total training time: 96.63 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 18.75, NNZs: 2821, Bias: 0.667188, T: 17246160, Avg. loss: 1.723694\n",
      "Total training time: 98.78 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 18.21, NNZs: 2821, Bias: 0.643335, T: 17584320, Avg. loss: 1.698469\n",
      "Total training time: 101.31 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 17.95, NNZs: 2821, Bias: 0.621898, T: 17922480, Avg. loss: 1.672197\n",
      "Total training time: 103.35 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 17.69, NNZs: 2821, Bias: 0.659006, T: 18260640, Avg. loss: 1.649055\n",
      "Total training time: 105.32 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 17.27, NNZs: 2821, Bias: 0.633045, T: 18598800, Avg. loss: 1.639145\n",
      "Total training time: 107.27 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 17.08, NNZs: 2821, Bias: 0.586992, T: 18936960, Avg. loss: 1.619530\n",
      "Total training time: 109.26 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 16.84, NNZs: 2821, Bias: 0.610232, T: 19275120, Avg. loss: 1.612382\n",
      "Total training time: 111.22 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 16.55, NNZs: 2821, Bias: 0.542427, T: 19613280, Avg. loss: 1.580211\n",
      "Total training time: 113.16 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 16.33, NNZs: 2821, Bias: 0.572535, T: 19951440, Avg. loss: 1.569726\n",
      "Total training time: 115.10 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 15.98, NNZs: 2821, Bias: 0.488784, T: 20289600, Avg. loss: 1.575026\n",
      "Total training time: 117.08 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 15.71, NNZs: 2821, Bias: 0.532989, T: 20627760, Avg. loss: 1.547378\n",
      "Total training time: 119.07 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 15.40, NNZs: 2821, Bias: 0.488270, T: 20965920, Avg. loss: 1.530214\n",
      "Total training time: 121.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 15.24, NNZs: 2821, Bias: 0.505495, T: 21304080, Avg. loss: 1.522405\n",
      "Total training time: 122.95 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 15.10, NNZs: 2821, Bias: 0.532749, T: 21642240, Avg. loss: 1.501542\n",
      "Total training time: 125.33 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 14.98, NNZs: 2821, Bias: 0.425098, T: 21980400, Avg. loss: 1.497212\n",
      "Total training time: 127.75 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 14.78, NNZs: 2821, Bias: 0.489363, T: 22318560, Avg. loss: 1.491101\n",
      "Total training time: 129.70 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 14.47, NNZs: 2821, Bias: 0.408336, T: 22656720, Avg. loss: 1.463413\n",
      "Total training time: 131.69 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 14.21, NNZs: 2821, Bias: 0.451575, T: 22994880, Avg. loss: 1.453219\n",
      "Total training time: 133.68 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 14.10, NNZs: 2821, Bias: 0.407701, T: 23333040, Avg. loss: 1.443868\n",
      "Total training time: 135.67 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 13.85, NNZs: 2821, Bias: 0.331874, T: 23671200, Avg. loss: 1.442865\n",
      "Total training time: 137.65 seconds.\n",
      "-- Epoch 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.83, NNZs: 2821, Bias: 0.429215, T: 24009360, Avg. loss: 1.423033\n",
      "Total training time: 139.64 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 13.62, NNZs: 2821, Bias: 0.398515, T: 24347520, Avg. loss: 1.421035\n",
      "Total training time: 141.61 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 13.40, NNZs: 2821, Bias: 0.343569, T: 24685680, Avg. loss: 1.416343\n",
      "Total training time: 143.57 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 13.32, NNZs: 2821, Bias: 0.351422, T: 25023840, Avg. loss: 1.391306\n",
      "Total training time: 145.66 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 13.01, NNZs: 2821, Bias: 0.326954, T: 25362000, Avg. loss: 1.390410\n",
      "Total training time: 147.73 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 12.96, NNZs: 2821, Bias: 0.341476, T: 25700160, Avg. loss: 1.372651\n",
      "Total training time: 150.02 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 12.95, NNZs: 2821, Bias: 0.412097, T: 26038320, Avg. loss: 1.371468\n",
      "Total training time: 152.65 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 12.60, NNZs: 2821, Bias: 0.288929, T: 26376480, Avg. loss: 1.365228\n",
      "Total training time: 154.74 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 12.44, NNZs: 2821, Bias: 0.317568, T: 26714640, Avg. loss: 1.351449\n",
      "Total training time: 156.72 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 12.32, NNZs: 2821, Bias: 0.299671, T: 27052800, Avg. loss: 1.348052\n",
      "Total training time: 158.74 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 12.24, NNZs: 2821, Bias: 0.343128, T: 27390960, Avg. loss: 1.336707\n",
      "Total training time: 160.74 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 12.12, NNZs: 2821, Bias: 0.295340, T: 27729120, Avg. loss: 1.330657\n",
      "Total training time: 162.74 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 12.05, NNZs: 2821, Bias: 0.293334, T: 28067280, Avg. loss: 1.319034\n",
      "Total training time: 164.73 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 11.77, NNZs: 2821, Bias: 0.209724, T: 28405440, Avg. loss: 1.318475\n",
      "Total training time: 166.72 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 11.81, NNZs: 2821, Bias: 0.306388, T: 28743600, Avg. loss: 1.297069\n",
      "Total training time: 168.69 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 11.71, NNZs: 2821, Bias: 0.301219, T: 29081760, Avg. loss: 1.311020\n",
      "Total training time: 170.67 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 11.44, NNZs: 2821, Bias: 0.270208, T: 29419920, Avg. loss: 1.302249\n",
      "Total training time: 172.63 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 11.39, NNZs: 2821, Bias: 0.231856, T: 29758080, Avg. loss: 1.284010\n",
      "Total training time: 174.68 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 11.38, NNZs: 2821, Bias: 0.247843, T: 30096240, Avg. loss: 1.280915\n",
      "Total training time: 177.24 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 11.21, NNZs: 2821, Bias: 0.299889, T: 30434400, Avg. loss: 1.274034\n",
      "Total training time: 179.47 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 10.99, NNZs: 2821, Bias: 0.246813, T: 30772560, Avg. loss: 1.278534\n",
      "Total training time: 181.44 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 11.07, NNZs: 2821, Bias: 0.237178, T: 31110720, Avg. loss: 1.259077\n",
      "Total training time: 183.45 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 10.86, NNZs: 2821, Bias: 0.217465, T: 31448880, Avg. loss: 1.261402\n",
      "Total training time: 185.46 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 10.82, NNZs: 2821, Bias: 0.193483, T: 31787040, Avg. loss: 1.247243\n",
      "Total training time: 187.48 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 10.66, NNZs: 2821, Bias: 0.243866, T: 32125200, Avg. loss: 1.244948\n",
      "Total training time: 189.48 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 10.55, NNZs: 2821, Bias: 0.190520, T: 32463360, Avg. loss: 1.235158\n",
      "Total training time: 191.49 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 10.53, NNZs: 2821, Bias: 0.227651, T: 32801520, Avg. loss: 1.237606\n",
      "Total training time: 193.49 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 10.38, NNZs: 2821, Bias: 0.225221, T: 33139680, Avg. loss: 1.235088\n",
      "Total training time: 195.50 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 10.37, NNZs: 2821, Bias: 0.286584, T: 33477840, Avg. loss: 1.218561\n",
      "Total training time: 197.46 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 10.29, NNZs: 2821, Bias: 0.191709, T: 33816000, Avg. loss: 1.221609\n",
      "Total training time: 199.44 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 10.11, NNZs: 2821, Bias: 0.206589, T: 34154160, Avg. loss: 1.208732\n",
      "Total training time: 201.87 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 10.10, NNZs: 2821, Bias: 0.197533, T: 34492320, Avg. loss: 1.206817\n",
      "Total training time: 204.32 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 9.95, NNZs: 2821, Bias: 0.213027, T: 34830480, Avg. loss: 1.207354\n",
      "Total training time: 206.31 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 10.02, NNZs: 2821, Bias: 0.263523, T: 35168640, Avg. loss: 1.197396\n",
      "Total training time: 208.31 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 9.87, NNZs: 2821, Bias: 0.206336, T: 35506800, Avg. loss: 1.208013\n",
      "Total training time: 210.33 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 9.75, NNZs: 2821, Bias: 0.190840, T: 35844960, Avg. loss: 1.190261\n",
      "Total training time: 212.33 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 9.60, NNZs: 2821, Bias: 0.169083, T: 36183120, Avg. loss: 1.187070\n",
      "Total training time: 214.34 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 9.54, NNZs: 2821, Bias: 0.184799, T: 36521280, Avg. loss: 1.176776\n",
      "Total training time: 216.37 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 9.56, NNZs: 2821, Bias: 0.167159, T: 36859440, Avg. loss: 1.169855\n",
      "Total training time: 218.42 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 9.55, NNZs: 2821, Bias: 0.167582, T: 37197600, Avg. loss: 1.176651\n",
      "Total training time: 220.44 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 9.42, NNZs: 2821, Bias: 0.146541, T: 37535760, Avg. loss: 1.169669\n",
      "Total training time: 222.43 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 9.38, NNZs: 2821, Bias: 0.169198, T: 37873920, Avg. loss: 1.164122\n",
      "Total training time: 224.40 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 9.36, NNZs: 2821, Bias: 0.179480, T: 38212080, Avg. loss: 1.152729\n",
      "Total training time: 226.63 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 9.20, NNZs: 2821, Bias: 0.136194, T: 38550240, Avg. loss: 1.160483\n",
      "Total training time: 229.21 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 9.20, NNZs: 2821, Bias: 0.219358, T: 38888400, Avg. loss: 1.150162\n",
      "Total training time: 231.30 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 9.18, NNZs: 2821, Bias: 0.130796, T: 39226560, Avg. loss: 1.149941\n",
      "Total training time: 233.32 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 9.11, NNZs: 2821, Bias: 0.158264, T: 39564720, Avg. loss: 1.143478\n",
      "Total training time: 235.35 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 9.04, NNZs: 2821, Bias: 0.153023, T: 39902880, Avg. loss: 1.141431\n",
      "Total training time: 237.37 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 8.99, NNZs: 2821, Bias: 0.171237, T: 40241040, Avg. loss: 1.141831\n",
      "Total training time: 239.37 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 8.94, NNZs: 2821, Bias: 0.153118, T: 40579200, Avg. loss: 1.139584\n",
      "Total training time: 241.37 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 8.89, NNZs: 2821, Bias: 0.123940, T: 40917360, Avg. loss: 1.129663\n",
      "Total training time: 243.42 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 8.84, NNZs: 2821, Bias: 0.133286, T: 41255520, Avg. loss: 1.129554\n",
      "Total training time: 245.44 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 8.77, NNZs: 2821, Bias: 0.191224, T: 41593680, Avg. loss: 1.131555\n",
      "Total training time: 247.45 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 8.72, NNZs: 2821, Bias: 0.142959, T: 41931840, Avg. loss: 1.118732\n",
      "Total training time: 249.43 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 8.61, NNZs: 2821, Bias: 0.133980, T: 42270000, Avg. loss: 1.123192\n",
      "Total training time: 251.51 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 8.52, NNZs: 2821, Bias: 0.077799, T: 42608160, Avg. loss: 1.118325\n",
      "Total training time: 254.12 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 8.53, NNZs: 2821, Bias: 0.097693, T: 42946320, Avg. loss: 1.105332\n",
      "Total training time: 256.33 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 8.48, NNZs: 2821, Bias: 0.139950, T: 43284480, Avg. loss: 1.109405\n",
      "Total training time: 258.35 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 8.48, NNZs: 2821, Bias: 0.145623, T: 43622640, Avg. loss: 1.107700\n",
      "Total training time: 260.36 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 8.42, NNZs: 2821, Bias: 0.124337, T: 43960800, Avg. loss: 1.105303\n",
      "Total training time: 262.38 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 8.37, NNZs: 2821, Bias: 0.130230, T: 44298960, Avg. loss: 1.105280\n",
      "Total training time: 264.42 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 8.33, NNZs: 2821, Bias: 0.088921, T: 44637120, Avg. loss: 1.093599\n",
      "Total training time: 266.45 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 8.21, NNZs: 2821, Bias: 0.057446, T: 44975280, Avg. loss: 1.103034\n",
      "Total training time: 268.48 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 8.18, NNZs: 2821, Bias: 0.100055, T: 45313440, Avg. loss: 1.089406\n",
      "Total training time: 270.50 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 8.19, NNZs: 2821, Bias: 0.096949, T: 45651600, Avg. loss: 1.084519\n",
      "Total training time: 272.51 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 8.14, NNZs: 2821, Bias: 0.076412, T: 45989760, Avg. loss: 1.093727\n",
      "Total training time: 274.50 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 8.13, NNZs: 2821, Bias: 0.074483, T: 46327920, Avg. loss: 1.078671\n",
      "Total training time: 276.52 seconds.\n",
      "-- Epoch 138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 8.03, NNZs: 2821, Bias: 0.107186, T: 46666080, Avg. loss: 1.083326\n",
      "Total training time: 279.04 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 8.00, NNZs: 2821, Bias: 0.121836, T: 47004240, Avg. loss: 1.082462\n",
      "Total training time: 281.44 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 7.93, NNZs: 2821, Bias: 0.064066, T: 47342400, Avg. loss: 1.078781\n",
      "Total training time: 283.44 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 7.92, NNZs: 2821, Bias: 0.086882, T: 47680560, Avg. loss: 1.069384\n",
      "Total training time: 285.48 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 7.86, NNZs: 2821, Bias: 0.060372, T: 48018720, Avg. loss: 1.075510\n",
      "Total training time: 287.54 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 7.80, NNZs: 2821, Bias: 0.068482, T: 48356880, Avg. loss: 1.066829\n",
      "Total training time: 289.57 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 7.76, NNZs: 2821, Bias: 0.049538, T: 48695040, Avg. loss: 1.058411\n",
      "Total training time: 291.58 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 7.77, NNZs: 2821, Bias: 0.069865, T: 49033200, Avg. loss: 1.064975\n",
      "Total training time: 293.60 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 7.66, NNZs: 2821, Bias: 0.092675, T: 49371360, Avg. loss: 1.068117\n",
      "Total training time: 295.63 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 7.70, NNZs: 2821, Bias: 0.107056, T: 49709520, Avg. loss: 1.061987\n",
      "Total training time: 297.67 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 7.62, NNZs: 2821, Bias: 0.082634, T: 50047680, Avg. loss: 1.063413\n",
      "Total training time: 299.67 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 7.58, NNZs: 2821, Bias: 0.062924, T: 50385840, Avg. loss: 1.056246\n",
      "Total training time: 301.68 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 7.51, NNZs: 2821, Bias: 0.094364, T: 50724000, Avg. loss: 1.054716\n",
      "Total training time: 304.06 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 7.46, NNZs: 2821, Bias: 0.070398, T: 51062160, Avg. loss: 1.051633\n",
      "Total training time: 306.60 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 7.41, NNZs: 2821, Bias: 0.083387, T: 51400320, Avg. loss: 1.046605\n",
      "Total training time: 308.63 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 7.42, NNZs: 2821, Bias: 0.097279, T: 51738480, Avg. loss: 1.043435\n",
      "Total training time: 310.66 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 7.38, NNZs: 2821, Bias: 0.069319, T: 52076640, Avg. loss: 1.044122\n",
      "Total training time: 312.71 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 7.45, NNZs: 2821, Bias: 0.063399, T: 52414800, Avg. loss: 1.046146\n",
      "Total training time: 314.74 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 7.37, NNZs: 2821, Bias: 0.071414, T: 52752960, Avg. loss: 1.041495\n",
      "Total training time: 316.77 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 7.30, NNZs: 2821, Bias: 0.086877, T: 53091120, Avg. loss: 1.037158\n",
      "Total training time: 318.85 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 7.28, NNZs: 2821, Bias: 0.036759, T: 53429280, Avg. loss: 1.035064\n",
      "Total training time: 320.90 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 7.27, NNZs: 2821, Bias: 0.029465, T: 53767440, Avg. loss: 1.039989\n",
      "Total training time: 322.92 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 7.25, NNZs: 2821, Bias: 0.051980, T: 54105600, Avg. loss: 1.027948\n",
      "Total training time: 324.93 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 7.22, NNZs: 2821, Bias: 0.074498, T: 54443760, Avg. loss: 1.030195\n",
      "Total training time: 326.94 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 7.20, NNZs: 2821, Bias: 0.072085, T: 54781920, Avg. loss: 1.029814\n",
      "Total training time: 329.20 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 7.21, NNZs: 2821, Bias: 0.075672, T: 55120080, Avg. loss: 1.025213\n",
      "Total training time: 331.83 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 7.13, NNZs: 2821, Bias: 0.049456, T: 55458240, Avg. loss: 1.031612\n",
      "Total training time: 333.92 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 7.09, NNZs: 2821, Bias: 0.016406, T: 55796400, Avg. loss: 1.026686\n",
      "Total training time: 335.96 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 7.03, NNZs: 2821, Bias: 0.059707, T: 56134560, Avg. loss: 1.018725\n",
      "Total training time: 338.02 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 7.03, NNZs: 2821, Bias: 0.021934, T: 56472720, Avg. loss: 1.018664\n",
      "Total training time: 340.08 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 7.03, NNZs: 2821, Bias: 0.030686, T: 56810880, Avg. loss: 1.021252\n",
      "Total training time: 342.17 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 7.02, NNZs: 2821, Bias: 0.048249, T: 57149040, Avg. loss: 1.016810\n",
      "Total training time: 344.31 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 6.98, NNZs: 2821, Bias: 0.048147, T: 57487200, Avg. loss: 1.014554\n",
      "Total training time: 346.37 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 6.93, NNZs: 2821, Bias: 0.068439, T: 57825360, Avg. loss: 1.015000\n",
      "Total training time: 348.42 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 6.84, NNZs: 2821, Bias: 0.054570, T: 58163520, Avg. loss: 1.011435\n",
      "Total training time: 350.44 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 6.81, NNZs: 2821, Bias: 0.025680, T: 58501680, Avg. loss: 1.003752\n",
      "Total training time: 352.44 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 6.84, NNZs: 2821, Bias: 0.020940, T: 58839840, Avg. loss: 1.007707\n",
      "Total training time: 354.68 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 6.83, NNZs: 2821, Bias: 0.019478, T: 59178000, Avg. loss: 1.006454\n",
      "Total training time: 357.31 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 6.80, NNZs: 2821, Bias: 0.030765, T: 59516160, Avg. loss: 1.003604\n",
      "Total training time: 359.43 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 6.72, NNZs: 2821, Bias: 0.049418, T: 59854320, Avg. loss: 1.003596\n",
      "Total training time: 361.47 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 6.67, NNZs: 2821, Bias: 0.021996, T: 60192480, Avg. loss: 1.005848\n",
      "Total training time: 363.52 seconds.\n",
      "Convergence after 178 epochs took 363.52 seconds\n"
     ]
    }
   ],
   "source": [
    "#========= Define Binary Labels =========#\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pairs_true_pred = []\n",
    "for each_seed in [42, 50, 123]:\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_tfidf, y_true, test_size=0.33, random_state=each_seed)\n",
    "    \n",
    "    skb = SelectKBest(chi2, k=np.round(X_train.shape[1]/4).astype(int) ).fit(X_train, y_train)\n",
    "    X_train = skb.transform(X_train)\n",
    "    X_test = skb.transform(X_test)\n",
    "    \n",
    "    pca = PCA(n_components=10)\n",
    "    pcscs = pca.fit(X_train.toarray())\n",
    "    X_tfidf_pca = pcscs.transform(X_train.toarray())\n",
    "    X_train = np.concatenate((X_train.toarray(), X_tfidf_pca), axis=1)\n",
    "    \n",
    "    X_test_pca = pcscs.transform(X_test.toarray())\n",
    "    X_test = np.concatenate((X_test.toarray(), X_test_pca), axis=1)\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3, verbose=1, class_weight=class_weights))\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    #pred_prob = clf.predict_proba(X_test)\n",
    "    pairs_true_pred.append([y_test, pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f27d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_pred = np.vstack([ np.vstack(each) for each in pairs_true_pred])\n",
    "np.save('SGD_PCA.npy', all_true_pred)\n",
    "\n",
    "# ============== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c496a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baccu:  0.587755934705\n",
      "recall:  0.524108643432\n",
      "prec:  0.176768482007\n",
      "f1:  0.26434979333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, precision_recall_curve, precision_recall_curve\n",
    "\n",
    "baccu=[]; recall = []; prec =[]; f1=[]; \n",
    "for each in range(0, 3):\n",
    "    baccu.append( balanced_accuracy_score(all_true_pred[2*each,:], all_true_pred[2*each+1,:]) )\n",
    "    recall.append( recall_score(all_true_pred[2*each,:], all_true_pred[2*each+1,:], average='binary') )\n",
    "    prec.append( precision_score(all_true_pred[2*each,:], all_true_pred[2*each+1,:], average='binary') )\n",
    "    f1.append( f1_score(all_true_pred[2*each,:], all_true_pred[2*each+1,:], average='binary') )\n",
    "    \n",
    "# Use AUC function to calculate the area under the curve of precision recall curve\n",
    "print(\"baccu: \", np.mean(baccu))\n",
    "print(\"recall: \", np.mean(recall))\n",
    "print(\"prec: \", np.mean(prec))\n",
    "print(\"f1: \", np.mean(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481bccdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc48aea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c104df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2620c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8162b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8dd6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ca25765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#========= Median positive and negative =========#\n",
    "\n",
    "X_train, X_test, y_train, y_test, weight_train, weight_test = \\\n",
    "    train_test_split(X_new, y_true, sample_weight, test_size=0.33, random_state=42)\n",
    "\n",
    "print( np.array([type(each)!=bool for each in y_true]).sum()  ) \n",
    "#class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                 np.unique(y_train),\n",
    "#                                                 y_train)\n",
    "#class_weights = dict(zip( np.unique(y_train), class_weights))\n",
    "#class_weights[True] = class_weights[True]*1.0\n",
    "##\n",
    "## Let's do sample weights\n",
    "#min_pos = df[ df['label'] == True]['up_votes'].min()\n",
    "#max_neg = df[ df['label'] == False]['up_votes'].max()\n",
    "#\n",
    "#\n",
    "#\n",
    "#print(dict(zip( np.unique(y_train), class_weights)) )\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51e2d0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                28120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 28,145\n",
      "Trainable params: 28,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(2, activation= 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy')])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db7ec85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "INFO:tensorflow:Assets written to: ./check_point/01_sim_tdidfNN_mdl.ckpt/assets\n",
      "9394/9394 - 23s - loss: 0.6653 - binary_accuracy: 0.6103 - val_loss: 0.6366 - val_binary_accuracy: 0.6348\n",
      "Epoch 2/70\n",
      "INFO:tensorflow:Assets written to: ./check_point/01_sim_tdidfNN_mdl.ckpt/assets\n",
      "9394/9394 - 22s - loss: 0.6475 - binary_accuracy: 0.6190 - val_loss: 0.6456 - val_binary_accuracy: 0.6286\n",
      "Epoch 3/70\n",
      "INFO:tensorflow:Assets written to: ./check_point/01_sim_tdidfNN_mdl.ckpt/assets\n",
      "9394/9394 - 23s - loss: 0.6428 - binary_accuracy: 0.6258 - val_loss: 0.6530 - val_binary_accuracy: 0.6217\n",
      "Epoch 4/70\n",
      "9394/9394 - 23s - loss: 0.6398 - binary_accuracy: 0.6360 - val_loss: 0.6422 - val_binary_accuracy: 0.6335\n",
      "Epoch 5/70\n",
      "INFO:tensorflow:Assets written to: ./check_point/01_sim_tdidfNN_mdl.ckpt/assets\n",
      "9394/9394 - 23s - loss: 0.6374 - binary_accuracy: 0.6406 - val_loss: 0.6702 - val_binary_accuracy: 0.6102\n",
      "Epoch 6/70\n",
      "9394/9394 - 23s - loss: 0.6354 - binary_accuracy: 0.6480 - val_loss: 0.6468 - val_binary_accuracy: 0.6396\n",
      "Epoch 7/70\n",
      "9394/9394 - 22s - loss: 0.6338 - binary_accuracy: 0.6517 - val_loss: 0.6672 - val_binary_accuracy: 0.6174\n",
      "Epoch 8/70\n",
      "9394/9394 - 23s - loss: 0.6321 - binary_accuracy: 0.6560 - val_loss: 0.6490 - val_binary_accuracy: 0.6378\n"
     ]
    }
   ],
   "source": [
    "# Callback define\n",
    "patience = 3; epochs = 70;\n",
    "checkpoint_filepath = './check_point/01_sim_tdidfNN_mdl.ckpt';\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='max')\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False, monitor='val_loss', mode='max', save_best_only=True)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train.toarray(), y_train, validation_data=(X_test.toarray(), y_test), \\\n",
    "                    epochs=epochs, batch_size=36, verbose=2, class_weight=class_weights,\\\n",
    "                    callbacks=[early_stopping, model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ad7e2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.610151479674\n",
      "balanced_accuracy_score:  0.609126626756\n",
      "88952 56753 8179 12673\n",
      "(166557, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load model and evaluate on test\n",
    "model = tf.keras.models.load_model('./check_point/01_sim_tdidfNN_mdl.ckpt')\n",
    "pred_test = model.predict(X_test.toarray()) > 0.5;\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "print( \"accuracy_score: \", accuracy_score(y_test, pred_test) )\n",
    "print( \"balanced_accuracy_score: \", balanced_accuracy_score(y_test, pred_test) )\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_test).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dabb813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try Google trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a999e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequential model\n",
    "# Use Token based text embedding trained on English Google News 7B corpus\n",
    "def create_model(): \n",
    "    \n",
    "    embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "    hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy')])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test seprate\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['title_clean'], y_true, test_size=0.33, random_state=42)\n",
    "\n",
    "# Callback define\n",
    "patience = 3; epochs = 70;\n",
    "checkpoint_filepath = './check_point/02_pre_nnlm-en-dim50_mdl.ckpt';\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='max')\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False, monitor='val_loss', mode='max', save_best_only=True)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), \\\n",
    "                    epochs=epochs, batch_size=64, verbose=2, sample_weight=weight_train,\\\n",
    "                    callbacks=[early_stopping, model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e218af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and evaluate on test\n",
    "model = tf.keras.models.load_model('./check_point/02_pre_nnlm-en-dim50_mdl.ckpt')\n",
    "pred_test = model.predict(X_test) > 0.5;\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "print( \"accuracy_score: \", accuracy_score(y_test, pred_test) )\n",
    "print( \"balanced_accuracy_score: \", balanced_accuracy_score(y_test, pred_test) )\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_test).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817637ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66704319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequential model\n",
    "# Use Token based text embedding trained on English Google News 7B corpus\n",
    "# Use pretrain embedding\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\n",
    "X_train = embed(df['title_clean'].values).numpy()\n",
    "\n",
    "# Train and Test seprate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_true, test_size=0.33, random_state=42)\n",
    "\n",
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense( 2, activation= 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense( 1, activation='sigmoid'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy')])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callback define\n",
    "patience = 3; epochs = 70;\n",
    "checkpoint_filepath = './check_point/03_preEmbed_nnlm-en-dim50_mdl.ckpt';\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='max')\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False, monitor='val_loss', mode='max', save_best_only=True)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), \\\n",
    "                    epochs=epochs, batch_size=64, verbose=2, sample_weight=weight_train,\\\n",
    "                    callbacks=[early_stopping, model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and evaluate on test\n",
    "model = tf.keras.models.load_model('./check_point/03_preEmbed_nnlm-en-dim50_mdl.ckpt')\n",
    "pred_test = model.predict(X_test) > 0.5;\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "print( \"accuracy_score: \", accuracy_score(y_test, pred_test) )\n",
    "print( \"balanced_accuracy_score: \", balanced_accuracy_score(y_test, pred_test) )\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_test).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2131a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28995c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc71fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770fab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737d263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d5978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8122b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['title_clean'], y_true, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f34469",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9740846",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train, y=y_train,\n",
    "                    epochs=150, batch_size=32, verbose=2, class_weight=class_weights,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_tfidf, df['up_votes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6744c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(X_tfidf).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_tfidf.sum(0).mean() )\n",
    "display(df['up_votes'].mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr = MLPRegressor(random_state=1, max_iter=500).fit(X_tfidf, df['up_votes'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7403f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df['up_votes'].values > df['up_votes'].values.mean()).sum())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = (df['up_votes'].values>np.quantile( df['up_votes'].values, 0.50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bd55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_tfidf, y_true )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdf43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Customize my own metrics\n",
    "\n",
    "class BalancedAccuracy(Metric):\n",
    "    def __init__(self, name=\"balanced_accuracy\", **kwargs):\n",
    "        super(BalancedAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.balanced_accuracy = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = y_pred.nupmy()\n",
    "        y_true = y_true.nupmy()\n",
    "\n",
    "        value = balanced_accuracy_score(y_true, y_pred, sample_weight)\n",
    "        #values = tf.multiply(values, sample_weight)\n",
    "        self.balanced_accuracy.assign_add((value))\n",
    "\n",
    "    def result(self):\n",
    "        return self.balanced_accuracy\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.balanced_accuracy.assign(0.0)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NetHawkes)",
   "language": "python",
   "name": "nethawkes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
